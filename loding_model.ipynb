{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/badeani/.virtualenvs/majordeploy/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-05-01 16:06:36.470179: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-01 16:06:42.878393: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "from transformers import T5Tokenizer, AutoTokenizer,MT5Tokenizer\n",
    "from transformers import MT5ForConditionalGeneration, AdamW\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "# pl.seed_everything(42)\n",
    "tf.random.set_seed(42)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
    "INPUT_MAX_LEN = 256 # Input length\n",
    "OUT_MAX_LEN = 128 # Output Length\n",
    "TRAIN_BATCH_SIZE = 16 # Training Batch Size\n",
    "VALID_BATCH_SIZE = 8 # Validation Batch Size\n",
    "EPOCHS = 5 # Number of Iteration\n",
    "learning_rate=1e-4\n",
    "weight_decay=0.1\n",
    "adam_epsilon=1e-8\n",
    "gradient_accumulation_steps=16\n",
    "fp_16=False\n",
    "\n",
    "\n",
    "MODEL_NAME = \"google/mt5-base\"\n",
    "tokenizer_name_or_path=\"google/mt5-base\"\n",
    "tokenizer = MT5Tokenizer.from_pretrained(MODEL_NAME, model_max_length= INPUT_MAX_LEN)\n",
    "\n",
    "\n",
    "class MT5Model(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = MT5ForConditionalGeneration.from_pretrained(MODEL_NAME, return_dict=True)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "\n",
    "        output = self.model(\n",
    "            input_ids=input_ids, \n",
    "            attention_mask=attention_mask, \n",
    "            labels=labels\n",
    "        )\n",
    "\n",
    "        return output.loss, output.logits\n",
    "\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "\n",
    "        input_ids = batch[\"inputs_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        labels= batch[\"targets\"]\n",
    "        loss, outputs = self(input_ids, attention_mask, labels)\n",
    "\n",
    "        \n",
    "        self.log(\"train_loss\", loss,on_step=True,on_epoch=True,prog_bar=True, logger=True)\n",
    "        \n",
    "        \n",
    "        return loss\n",
    "\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        input_ids = batch[\"inputs_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        labels= batch[\"targets\"]\n",
    "        loss, outputs = self(input_ids, attention_mask, labels)\n",
    "\n",
    "        self.log(\"val_loss\", loss,on_epoch=True, prog_bar=True, logger=True)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"Prepare optimizer and schedule (linear warmup and decay)\"\n",
    "\n",
    "        model = self.model\n",
    "        no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "        optimizer_grouped_parameters = [\n",
    "            {\n",
    "                \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "                \"weight_decay\": weight_decay,\n",
    "            },\n",
    "            {\n",
    "                \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "                \"weight_decay\": 0.1,\n",
    "            },\n",
    "        ]\n",
    "        optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate, eps=adam_epsilon)\n",
    "        self.opt = optimizer\n",
    "        return [optimizer]\n",
    "        # return AdamW(self.parameters(), lr=0.0001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "MODEL_NAME = \"google/mt5-base\"\n",
    "tokenizer_name_or_path=\"google/mt5-base\"\n",
    "tokenizer = MT5Tokenizer.from_pretrained(MODEL_NAME, model_max_length= INPUT_MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model=joblib.load('..\\mt5base_final_model.joblib')\n",
    "model=joblib.load('../mt5base_final_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_paraphrase(question1):\n",
    "\n",
    "    inputs_encoding =  tokenizer(\n",
    "        question1,\n",
    "        add_special_tokens=True,\n",
    "        max_length= 256,\n",
    "        padding = 'max_length',\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors=\"pt\" \n",
    "        )\n",
    "\n",
    "\n",
    "    generate_ids = model.model.generate(\n",
    "        input_ids = inputs_encoding[\"input_ids\"],\n",
    "        attention_mask = inputs_encoding[\"attention_mask\"],\n",
    "        do_sample=True,\n",
    "        max_length=64,\n",
    "        top_k=40,\n",
    "        top_p=0.98,\n",
    "        early_stopping=True,\n",
    "        num_return_sequences = 1,\n",
    "        no_repeat_ngram_size=2,\n",
    "        )\n",
    "\n",
    "    preds = [\n",
    "        tokenizer.decode(gen_id,\n",
    "        skip_special_tokens=True, \n",
    "        clean_up_tokenization_spaces=True)\n",
    "        for gen_id in generate_ids\n",
    "    ]\n",
    "\n",
    "    return \"\".join(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "उनीहरूको सेवा सुविधा रोकिएको छ।\n"
     ]
    }
   ],
   "source": [
    "text='उनीहरूको सेवा सुविधा भने रोकिएको थियो ।'\n",
    "print(generate_paraphrase(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "तपाईंले क्रस र प्रेमको भिन्नता कसरी भन्नुहुन्छ?\n"
     ]
    }
   ],
   "source": [
    "text='क्रस र प्रेम बीचको भिन्नता कसरी बताउनुहुन्छ?'\n",
    "print(generate_paraphrase(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model = MT5Model.load_from_checkpoint(dir_to_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "majordeploy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bc58931512d54001f233f32c5448ffc9d86d18fc167b8e4db93f4f291b4f8cc0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
